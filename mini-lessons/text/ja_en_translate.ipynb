{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Machine-Learning-Tokyo/MLT-x-fastai/blob/master/fastai-text-data-examples-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i8F6rk1YwJ9P"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btS8qaALwJ9b"
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LkXYHQhcwKAU"
   },
   "source": [
    "## Seq2Seq\n",
    "\n",
    "A sequence-to-sequence model is a model that takes a sequence of items and outputs another sequence of items using two networks that are trained end-to-end. This is perfect for machine translation since input sequences are directly related to output sequences. We will looking at preparing a dataset for Machine Translation task and implementing a seq2seq model. We will be using the parallel corpus available from [here](ftp://ftp.monash.edu/pub/nihongo/examples.utf.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5KcBSgDwKAU"
   },
   "outputs": [],
   "source": [
    "def make_corpus(corpus_path):\n",
    "    corpus = corpus_path.open().readlines()\n",
    "    data_pair = []\n",
    "    pat = r'#ID.+\\n'\n",
    "    for c in corpus:\n",
    "        if 'A: ' in c:\n",
    "            clean_c = c.replace('A: ','')\n",
    "            res = re.search(pat,clean_c)\n",
    "            clean_c = clean_c.replace(res.group(0),'').split('\\t')\n",
    "            data_pair.append((clean_c[0],clean_c[1]))\n",
    "    return pd.DataFrame(data_pair,columns=['ja','en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBvnts3UwKAY",
    "outputId": "82c45ceb-1eae-44e3-e742-0d0ca8e2fb65"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ja</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ムーリエルは２０歳になりました。</td>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>すぐに戻ります。</td>\n",
       "      <td>I will be back soon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>すぐに諦めて昼寝をするかも知れない。</td>\n",
       "      <td>I may give up soon and just nap instead.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>愛してる。</td>\n",
       "      <td>I love you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ログアウトするんじゃなかったよ。</td>\n",
       "      <td>I shouldn't have logged off.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ja                                        en\n",
       "0    ムーリエルは２０歳になりました。                        Muiriel is 20 now.\n",
       "1            すぐに戻ります。                      I will be back soon.\n",
       "2  すぐに諦めて昼寝をするかも知れない。  I may give up soon and just nap instead.\n",
       "3               愛してる。                               I love you.\n",
       "4    ログアウトするんじゃなかったよ。              I shouldn't have logged off."
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_corpus(path/'examples.utf')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Kvee5X9wKAa",
    "outputId": "3890af75-7119-4f9d-bccf-0d1c27a442e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149784"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9PxAEtXwKAd",
    "outputId": "e75f4df0-9e53-4bbd-fc86-daf64ff6a1c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149784"
      ]
     },
     "execution_count": 286,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_idxs = np.random.choice(np.arange(len(df)), int(0.1*len(df)),replace=False)\n",
    "train_idxs = [i for i in np.arange(len(df)) if i not in valid_idxs]\n",
    "len(train_idxs) + len(valid_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1UYkzBUwKAg"
   },
   "outputs": [],
   "source": [
    "#collation function and databunch code borrowed from here: \n",
    "#https://github.com/ohmeow/seq2seq-pytorch-fastai/blob/master/seq2seq-rnn-attn.ipynb\n",
    "\n",
    "def seq2seq_pad_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=False, \n",
    "                        include_targets=True, include_lengths=False, include_masks=False,\n",
    "                        backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
    "    \n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    \n",
    "    samples = to_data(samples)\n",
    "    samples.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    \n",
    "    x_lens = [len(s[0]) for s in samples]\n",
    "    x_max_len = max(x_lens)\n",
    "    x_res = torch.zeros(len(samples), x_max_len).long() + pad_idx\n",
    "    \n",
    "    y_lens = [len(s[1]) for s in samples]\n",
    "    y_max_len = max(y_lens)\n",
    "    y_res = torch.zeros(len(samples), y_max_len).long() + pad_idx\n",
    "    \n",
    "    if backwards: pad_first = not pad_first\n",
    "        \n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            x_res[i,-len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,-len(s[1]):] = LongTensor(s[1])\n",
    "        else:         \n",
    "            x_res[i,:len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,:len(s[1]):] = LongTensor(s[1])\n",
    "            \n",
    "    if backwards: res = res.flip(1)\n",
    "        \n",
    "    x = [x_res]\n",
    "    if (include_targets): x += [y_res.clone()]\n",
    "    if (include_lengths): x += [torch.tensor(x_lens), torch.tensor(y_lens)]\n",
    "    if (include_masks): x += [x_res != pad_idx, y_res != pad_idx]\n",
    "    \n",
    "    return x, y_res\n",
    "\n",
    "\n",
    "class Seq2SeqDataBunch(DataBunch):\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, \n",
    "               path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1, pad_first=False, \n",
    "               device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
    "        \n",
    "        \"\"\"Function that transform the `datasets` in a `DataBunch` for seq2seq task. \n",
    "        Passes `**dl_kwargs` on to `DataLoader()`\"\"\"\n",
    "        \n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        \n",
    "        collate_fn = partial(seq2seq_pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        \n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        \n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9_Q7LXJwKAi"
   },
   "outputs": [],
   "source": [
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FpOxgbMTwKAk"
   },
   "outputs": [],
   "source": [
    "en_tok = Tokenizer(lang='en')\n",
    "en_procs = [TokenizeProcessor(tokenizer=en_tok, include_bos=True, include_eos=True), \n",
    "            NumericalizeProcessor(min_freq=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jo-p4T_pwKAm"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(MeCabTokenizer, 'ja')\n",
    "ja_procs = [TokenizeProcessor(tokenizer=tokenizer,include_bos=True, include_eos=True), NumericalizeProcessor(max_vocab=30000,min_freq=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3WuE-cawKAn"
   },
   "outputs": [],
   "source": [
    "en_il = Seq2SeqTextList.from_df(df, path, cols=['en'], processor=en_procs).process().split_by_idxs(train_idxs,valid_idxs)\n",
    "ja_il = Seq2SeqTextList.from_df(df, path, cols=['ja'], processor=ja_procs).process().split_by_idxs(train_idxs,valid_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lp77piH5wKAp"
   },
   "outputs": [],
   "source": [
    "tr_ll = LabelList(en_il.train,ja_il.train)\n",
    "val_ll = LabelList(en_il.valid,ja_il.valid)\n",
    "lls = LabelLists(path,train=tr_ll,valid=val_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HU6eew3wKAr"
   },
   "outputs": [],
   "source": [
    "seq2seq_data = lls.databunch(bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgDqNCjywKAs",
    "outputId": "38610cfa-b5cc-4ad0-9d41-dd8896cba213"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj muiriel is 20 now . xxeos,\n",
       " Text xxbos ムーリエル は ２ ０ 歳 に なり まし た 。 xxeos)"
      ]
     },
     "execution_count": 291,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_data.train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XejAD33ZwKAu"
   },
   "outputs": [],
   "source": [
    "en_vecs,_,dim_en_vec = load_vectors('data/wiki-news-300d-1M.vec')\n",
    "j_vecs,_,dim_j_vec = load_vectors('data/cc.ja.300.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pydn2l1bwKAw"
   },
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    if vecs is None: return emb\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w])\n",
    "        except: miss.append(w)\n",
    "    print('Number of unknowns in data: {}'.format(len(miss)))\n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1roMu9AwKAx"
   },
   "outputs": [],
   "source": [
    "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
    "def rand_p(*sz): return nn.Parameter(rand_t(*sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCIfiPkVwKA2"
   },
   "outputs": [],
   "source": [
    "class Seq2SeqAttention(nn.Module):\n",
    "    def __init__(self,int2en,int2j,em_sz,j_vecs=None,en_vecs=None,nh=128,out_sl=25,dropf=1,nl=2):\n",
    "        super().__init__()\n",
    "        #encoder\n",
    "        self.nl,self.nh,self.em_sz,self.out_sl = nl,nh,em_sz,out_sl\n",
    "        self.emb_enc = create_emb(en_vecs,int2en,em_sz)\n",
    "        self.emb_drop = nn.Dropout(0.15*dropf)\n",
    "        self.encoder = nn.GRU(em_sz,nh,num_layers=nl,dropout=0.25*dropf, bidirectional=True,batch_first=True)\n",
    "        #decoder\n",
    "        self.emb_dec = create_emb(j_vecs,int2j,em_sz)\n",
    "        self.decoder = nn.GRU(em_sz,nh*2,num_layers=nl,dropout=0.25*dropf,batch_first=True)\n",
    "        self.out_drop = nn.Dropout(0.35*dropf)\n",
    "        self.out = nn.Linear(nh*2,len(int2j))\n",
    "        #attention layer\n",
    "        self.W1 = rand_p(nh*2, nh*2) #parameter\n",
    "        self.l2 = nn.Linear(nh*2, nh*2)\n",
    "        self.l3 = nn.Linear(em_sz+nh*2, em_sz)\n",
    "        self.V = rand_p(nh*2) #parameter\n",
    "        self.targets = None\n",
    "    \n",
    "    def forward(self,inp,y=None):\n",
    "        self.targets = y\n",
    "        bs,sl = inp.size()\n",
    "        emb_in = self.emb_drop(self.emb_enc(inp))\n",
    "        h_n = self.initHidden(bs)\n",
    "        enc_out, h_n = self.encoder(emb_in,h_n)\n",
    "        h_n = h_n.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
    "        \n",
    "        dec_inp = torch.zeros(bs).long().cuda()\n",
    "        res,attns = [], []\n",
    "        #multiply by parameter\n",
    "        w1e = enc_out @ self.W1\n",
    "        for i in range(self.out_sl):\n",
    "            #linear layer \n",
    "            w2h = self.l2(h_n[-1])\n",
    "            #non-linear activation to calculate score\n",
    "            u = torch.tanh(w1e + w2h.unsqueeze(1))\n",
    "            #softmax to make them into probs\n",
    "            a = F.softmax(u @ self.V, 0)\n",
    "            attns.append(a)\n",
    "            #multiply each vector by scores and then add them up\n",
    "            Xa = (a.unsqueeze(2) * enc_out).sum(1)\n",
    "            dec_emb = self.emb_dec(dec_inp)\n",
    "            #linear layer to reduce dimensions\n",
    "            wgt_enc = self.l3(torch.cat([dec_emb, Xa], 1))\n",
    "            outp,h_n = self.decoder(wgt_enc.unsqueeze(1),h_n)\n",
    "            outp = self.out(self.out_drop(outp[:,0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = outp.data.max(1)[1]\n",
    "            if i >=self.targets.size(1):break\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (random.random() > 0.5) and self.targets is not None: dec_inp=y[:,i] \n",
    "        return torch.stack(res).transpose(1,0)\n",
    "        \n",
    "    def initHidden(self,bs):\n",
    "        return torch.zeros([self.nl*2,bs,self.nh]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tgE3MgKewKA4"
   },
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    bs,sl = target.size()\n",
    "    bs_in,sl_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,sl-sl_in,0,0))\n",
    "    input = input[:,:sl,:]\n",
    "    return F.cross_entropy(input.contiguous().view(-1,nc), target.contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFmsFBajwKA6"
   },
   "outputs": [],
   "source": [
    "class TeacherForcingCallback(LearnerCallback):\n",
    "    learn:Learner\n",
    "        \n",
    "    def on_batch_begin(self, train, **kwargs):\n",
    "        learn.model.targets = kwargs['last_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkG597I4wKA9",
    "outputId": "3ef8c0a6-3dc7-4e61-eb65-6cdf9bb13279"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqAttention(\n",
       "  (emb_enc): Embedding(21395, 300, padding_idx=1)\n",
       "  (emb_drop): Dropout(p=0.15)\n",
       "  (encoder): GRU(300, 128, num_layers=2, batch_first=True, dropout=0.25, bidirectional=True)\n",
       "  (emb_dec): Embedding(30004, 300, padding_idx=1)\n",
       "  (decoder): GRU(300, 256, num_layers=2, batch_first=True, dropout=0.25)\n",
       "  (out_drop): Dropout(p=0.35)\n",
       "  (out): Linear(in_features=256, out_features=30004, bias=True)\n",
       "  (l2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (l3): Linear(in_features=556, out_features=300, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 295,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq = Seq2SeqAttention(seq2seq_data.train_ds.x.vocab.itos,seq2seq_data.train_ds.y.vocab.itos,300,en_vecs=None,j_vecs=None)\n",
    "seq2seq.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tco_NyzwKBA"
   },
   "outputs": [],
   "source": [
    "learn = Learner(seq2seq_data,seq2seq)\n",
    "learn.loss_func = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Pt8Oc0awKBD"
   },
   "outputs": [],
   "source": [
    "learn.callbacks.append(TeacherForcingCallback(learn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwqdx2n7wKBH",
    "outputId": "8e357689-3322-40af-c1a9-b3914fbab3f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCzEk-vPwKBK",
    "outputId": "03288ac5-1813-4a03-e6f7-4610ccfb2bf4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyZC6HMdwKBP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, 3e-3, moms=(0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmsVuYICgWea"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "LkXYHQhcwKAU",
    "b0_QNFnPwKBT"
   ],
   "include_colab_link": true,
   "name": "fastai-text-data-examples.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
