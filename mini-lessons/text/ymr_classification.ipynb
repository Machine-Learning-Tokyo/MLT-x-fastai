{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Machine-Learning-Tokyo/MLT-x-fastai/blob/master/fastai-text-data-examples-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i8F6rk1YwJ9P"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btS8qaALwJ9b"
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ZOWlQymwJ9g"
   },
   "source": [
    "Content from this notebook has been inspired from the fast.ai course-v3 Part 1. In this notebook we'll go through some standard NLP tasks using lessons from fast.ai. We will learn about Transfer Learning in NLP, creating `TextDataBunch` objects, training a model for text classification task and a Sequence2Sequence task We will see how the `fastai` library uses a style called the Data Block API to simplify the process of prepping data for different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RAAKTmvMwJ9i"
   },
   "outputs": [],
   "source": [
    "#Google Colab notes: imports for uploading files\n",
    "#from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQMt1sO6wUHO"
   },
   "outputs": [],
   "source": [
    "#Google Colab notes: make data directory\n",
    "#!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FbtcGVLWwJ9p"
   },
   "outputs": [],
   "source": [
    "path = Path('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "de1RHLVWwJ9t"
   },
   "source": [
    "## Language Modeling\n",
    "\n",
    "One of the most common tasks done in NLP is called language modeling. A language model is an NLP model which learns to predict the next word in a sentence. We do this is because we assume that if a language model is quite accurate at guessing the next probable word in a sentnce, it needs a lot of world knowledge and a deep understanding of grammar, semantics, and other elements of natural language.\n",
    "\n",
    "We will show how to train a simple language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "562r2FPmwJ9u"
   },
   "outputs": [],
   "source": [
    "#!wget https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
    "#!mv nietzsche.txt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "TvqPqmt0wJ91",
    "outputId": "23b97728-6ca4-4e29-b1ba-3b7c813cbcb1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PREFACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nSUPPOSING that Truth is a woman--what then? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sils Maria Upper Engadine, JUNE, 1885.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nCHAPTER I. PREJUDICES OF PHILOSOPHERS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                                            PREFACE\n",
       "1  \\nSUPPOSING that Truth is a woman--what then? ...\n",
       "2             Sils Maria Upper Engadine, JUNE, 1885.\n",
       "3                                                   \n",
       "4            \\nCHAPTER I. PREJUDICES OF PHILOSOPHERS"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(open(path/'nietzsche.txt').read().split('\\n\\n'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0LSpb-SwJ97"
   },
   "outputs": [],
   "source": [
    "bs=64\n",
    "data_lm = (TextList.from_df(df,path,cols=[0])\n",
    "                   .split_by_rand_pct(0.1)\n",
    "                   .label_for_lm()\n",
    "                   .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "JJf8PW9cwJ-A",
    "outputId": "5ec5e34e-faca-4a35-af42-0b998aec5960"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>unseemly methods for \\n  xxunk a woman ? xxmaj certainly she has never allowed herself to be won ; and \\n  at present every kind of dogma stands with sad and xxunk xxunk -- xxup if , \\n  indeed , it stands at all ! xxmaj for there are xxunk who maintain that it \\n  has fallen , that all dogma lies on the ground --</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>an opinion is life - xxunk , life - preserving , \\n  species - preserving , perhaps species - rearing , and we are fundamentally \\n  inclined to maintain that the xxunk opinions ( to which the synthetic \\n  judgments a priori belong ) , are the most indispensable to us , that \\n  without a recognition of logical fictions , without a comparison of \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>, the \\n  will to \" creation of the world , \" the will to the causa xxunk . xxbos 10 . xxmaj the eagerness and subtlety , i should even say craftiness , with \\n  which the problem of \" the real and the apparent world \" is xxunk with at \\n  present throughout xxmaj europe , furnishes food for thought and attention ; and \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>belief ought to be xxunk from science ! xxmaj between \\n  ourselves , it is not at all necessary to get rid of \" the soul \" thereby , \\n  and thus renounce one of the oldest and most xxunk hypotheses -- as \\n  happens frequently to the clumsiness of xxunk , who can hardly \\n  touch on the soul without immediately losing it . xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>alone is really known to us , absolutely and \\n  completely known , without deduction or addition . xxmaj but it again and \\n  again seems to me that in this case xxmaj schopenhauer also only did what \\n  philosophers are in the habit of doing -- he seems to have adopted a \\n  xxup popular xxup prejudice and exaggerated it . xxmaj willing seems to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VgctHNM_wJ-K"
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM,drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "mKZQVe88wJ-S",
    "outputId": "79059f27-394d-4a69-fc8d-c08d3d3f02d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiKDFAoiIjJIoSAiIoP+P50J1sOX+8uCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "VH1Rrf2mwJ-a",
    "outputId": "0debccd6-8716-4222-fab2-110bdc704210"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.749605</td>\n",
       "      <td>4.329587</td>\n",
       "      <td>0.213988</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1,1e-2,moms=(0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "lLQSsIHZwJ-h",
    "outputId": "fea85c45-44ac-45d8-b8f5-1c631e0063bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.242284</td>\n",
       "      <td>3.997777</td>\n",
       "      <td>0.256920</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.024162</td>\n",
       "      <td>3.899869</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.843143</td>\n",
       "      <td>3.868506</td>\n",
       "      <td>0.266295</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.600221</td>\n",
       "      <td>3.874033</td>\n",
       "      <td>0.270610</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4,3e-3,moms=(0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "_Djk9URLwJ-m",
    "outputId": "4e0f7e22-ca27-4d01-9ce9-3c60db7c2c28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is perhaps just dawning on five or six minds . Yet the most extensive fact of the \\n  circumstances has been been provided after the accident of More \\n  and Bell of Saint fire in whose grace and hatred of \\n  period talk represents their goal : where the populace has grown \\n  and there is well enough with regard to the HIGHER \\n  world of the present school , in whom a number could not , step home , be learnt \\n  to live as maid and lover and of distinction : \\n  hitherto , of course , in speaking hours and habits'"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('It is perhaps just dawning on five or six minds',n_words=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqQ2WuWKwJ-u"
   },
   "source": [
    "## Tokenization and Numericalization\n",
    "The most common preprocessing on NLP tasks in tokenization i.e splitting the sentence into words. This is much easier in space-seperated words like English however, for Japanese we require Morphological Analysis tools to get words from sentences.\n",
    "\n",
    "Numericalizing in the second preprocessing step. Since models can only take numbers as inputs, we make a dictionary mapping unique words to indices and replace the words with the words in the sentence with their corresponding index. Here we limit our dictionary size to 60000 words that appear at least twice in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nppsyhBqxQyT"
   },
   "outputs": [],
   "source": [
    "#Google Colab notes: install dependencies for mecab tokenizer\n",
    "#!sudo apt install swig\n",
    "#!sudo apt install mecab\n",
    "#!sudo apt install libmecab-dev\n",
    "#!sudo apt install mecab-ipadic-utf8\n",
    "#!sudo pip3 install mecab-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZvJ9IAkxcGi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZKaNpATwJ-u"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import MeCab\n",
    "\n",
    "tagger = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "class MeCabTokenizer(BaseTokenizer):\n",
    "    def __init__(self, lang:str):\n",
    "        self.lang = 'ja'\n",
    "    \n",
    "    def add_special_cases(self, toks:Collection[str]): pass\n",
    "    \n",
    "    def tokenizer(self,raw_sentence):\n",
    "        result = tagger.parse(raw_sentence)\n",
    "        words = result.split()\n",
    "        if len(words) == 0:\n",
    "            return []\n",
    "        if words[-1] == \"\\n\":\n",
    "            words = words[:-1]\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5t-GgbaowJ_K"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(MeCabTokenizer, 'ja')\n",
    "processor = [TokenizeProcessor(tokenizer=tokenizer), NumericalizeProcessor(max_vocab=60000,min_freq=2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7BF02EpwJ-y"
   },
   "source": [
    "## Text Classification\n",
    "One particular area that was challenging until recently with deep learning for NLP, was text classification.\n",
    "\n",
    "Similar to classifying images in text we can also use transfer learning to train accurate classifiers with few training examples. We will leverage weights from a language model trained on a large corpus as our pretrained weights. We will fine-tune the language model to our target dataset, attach a classification layer to our model and train by gradual unfreezing. The text classifying task will be sentiment analysis on Yahoo Movie Reviews. The data can be downloaded from this [repository](https://github.com/dennybritz/sentiment-analysis/tree/master/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Ndi1UyJwJ-0"
   },
   "outputs": [],
   "source": [
    "#Google Colab Notes: download data and upload them into your notebook environment\n",
    "#files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udgse3lozEiv"
   },
   "outputs": [],
   "source": [
    "#Google Colab Notes: uncompress data and move to data directory\n",
    "#!tar xvzf yahoo-movie-reviews.json.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URd13SIGwJ-3"
   },
   "outputs": [],
   "source": [
    "def load_ymr_data(path):\n",
    "    with path.open() as f:\n",
    "        data = pd.read_json(f)\n",
    "        data.movieName = data.movieName.str.strip()\n",
    "        data.text = data.text.str.strip()\n",
    "        data.title = data.title.str.strip()\n",
    "        data = data[data.text.str.len() > 0]\n",
    "        data.url = data.url.str.strip()\n",
    "    return data\n",
    "\n",
    "def make_polar(data, balance=True):\n",
    "    data_polar = data.loc[data.rating != 3].copy()\n",
    "    data_polar.loc[data_polar.rating <= 2, 'rating'] = 0\n",
    "    data_polar.loc[data_polar.rating >= 4, 'rating'] = 1\n",
    "    if balance:\n",
    "        # Subsample - We want the same number of positive and negative examples\n",
    "        grouped_ratings = data_polar.groupby('rating')\n",
    "        K = grouped_ratings.rating.count().min()\n",
    "        indices = itertools.chain(\n",
    "            *[np.random.choice(v, K, replace=False) for k, v in grouped_ratings.groups.items()])\n",
    "        data_polar = data_polar.reindex(indices).copy()\n",
    "    return data_polar\n",
    "\n",
    "\n",
    "mov_df = load_ymr_data(path/'yahoo-movie-reviews.json')\n",
    "mov_df_polar = make_polar(mov_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jTE7YgUwJ_A"
   },
   "outputs": [],
   "source": [
    "#mov_df_polar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zXLt6RmwJ_R"
   },
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BjtxfW2RwJ_Y"
   },
   "outputs": [],
   "source": [
    "data_lm = (TextList.from_df(mov_df_polar,path,cols=['text'],processor=processor)\n",
    "                   .split_by_rand_pct(0.1)\n",
    "                   .label_for_lm()\n",
    "                   .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "8VFZlZJRwJ_g",
    "outputId": "8403edce-33d6-41b3-be0d-c62912449e7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>とか 、 好き か 嫌い か という 以前 に 、 映画 の 質 そのもの に 疑問 。 日本映画 史 に 残っ て いく はず の 作品 だけ に … … 、 残念 。 とにもかくにも 、 演出 と 脚本 が ひど すぎる 。 言い出し たら 切り が ない ぐらい だ が 、 まずは 、 なんと いう か 、 「 古い 」 。 （ あるいは 、 いわゆる 「 ベタ 」 。 ）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>感情 移入 する 人 を 選ぶ な～ と 思い ます 。 いい 子 ばかり が 出る 登場人物 は 、 盛り上がり に も かけ 、 当時 の 洗濯機 や 台所 まわり の 様子 、 風景 を 見 て 、 「 懐かしい わ～ 」 や 「 あの 頃 は ～」 という こと しか 残ら ない 。 テレビ の 2時間 の 枠 の アニメ で 充分 です 。 まわり の 子ども さん は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>に は 「 やめ た 方 が いい ！ 」 と 声 を 大 に し て 言い たい ！ ！ 大人 も 子供 も 楽しめ ない 映画 だ と 、 私 は 思い ます ！ 最後 に 余談 です が 、 「 xxunk 」 で この 映画 を 紹介 し た とき に 、 佐 ○ 木 ｱﾅ が 「 私 は これ を 観 て \" xxup et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>の 、 偏見 という の は 多かれ 少なかれ ある と 思い ます 。 自分 達 が 美化 さ れ 過ぎ それ に 、 いくら 不遇 な 過去 へ の 孤独感 、 人 と 上手く コミュニケーション が でき ない もどかし さ が ある と は いえ あんな 形 で 、 聾唖 少女 の 痛み を 演じ させる なんて 。 健常者 より も 、 障害 を 持た れる 方 は 、 ずっと</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>終わり ？ まじ か よ 。 」 「 なに これ ？ こんなに 長い 時間 かけて こんな 終わり ？ 」 って 声 が かなり あり まし た 。 来年 の ４月 に パート ２ が やる よう です が 、 その 頃 に は レンタル で て いる ので 、 今回 は わざわざ お金 だして 見る ほど で も ない です 。 xxbos 直感 で くだらな さ そう な 作品 だ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_83e7pMewJ_l"
   },
   "source": [
    "We will initialize our model with weights from a language model trained on Japanese Wikipedia. You can download them from [here](https://drive.google.com/open?id=1KRUEV_3R-JVhcftvWJ66rwU7e_EZWtxE) and you need to place the files in the `data/models/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "axYJrS2jwJ_l"
   },
   "outputs": [],
   "source": [
    "#Google colab notes: upload model files\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#!cp /content/drive/My\\ Drive/ja-wiki-awdlstm-model/ja-wiki-itos.pkl \n",
    "#!cp /content/drive/My\\ Drive/ja-wiki-awdlstm-model/ja-wiki.pth ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gKzpoyBl8aZi"
   },
   "outputs": [],
   "source": [
    "#!mv ja-wiki-itos.pkl data/models\n",
    "#!mv ja-wiki.pth data/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDROqQ_xwJ_n"
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM,pretrained_fnames=['ja-wiki','ja-wiki-itos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8t935fGjwJ_p",
    "outputId": "c4cd0e4c-d15c-4814-9df6-03c06c083bd2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 04:03 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.375677</td>\n",
       "      <td>4.124529</td>\n",
       "      <td>0.292882</td>\n",
       "      <td>04:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1,1e-2,moms=(0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85HGj4ATwJ_w",
    "outputId": "9f02dc66-ee30-49e9-a46f-f0bcbde85059"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 37:12 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.069916</td>\n",
       "      <td>3.950010</td>\n",
       "      <td>0.312577</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.984557</td>\n",
       "      <td>3.836064</td>\n",
       "      <td>0.324826</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.870781</td>\n",
       "      <td>3.762562</td>\n",
       "      <td>0.333079</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.768262</td>\n",
       "      <td>3.712374</td>\n",
       "      <td>0.338276</td>\n",
       "      <td>04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.714551</td>\n",
       "      <td>3.674273</td>\n",
       "      <td>0.342792</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.596981</td>\n",
       "      <td>3.647418</td>\n",
       "      <td>0.346149</td>\n",
       "      <td>04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.517474</td>\n",
       "      <td>3.636053</td>\n",
       "      <td>0.347601</td>\n",
       "      <td>04:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.468837</td>\n",
       "      <td>3.635810</td>\n",
       "      <td>0.347985</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(8,3e-3,moms=(0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2kbsexYwJ_3"
   },
   "outputs": [],
   "source": [
    "learn.save('ymr')\n",
    "learn.save_encoder('ymr_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FarNDkEYwJ_7"
   },
   "outputs": [],
   "source": [
    "data_clas = (TextList.from_df(mov_df_polar,path,cols=['text'],vocab=data_lm.vocab,processor=processor)\n",
    "                   .split_by_rand_pct(0.1)\n",
    "                   .label_from_df(cols=['rating'])\n",
    "                   .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0F0IN2LwJ_9",
    "outputId": "20f1aebe-decc-4669-c64e-7dbed3d83285"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos ・ 過去 の 行い と 罪 の 意識 から 強 さ の 裏 で 自分 の 命 を 軽 ん じ て い た 剣心 が 、 師匠 と 剣 を 交える うち に 「 死に たく ない ！ 」 「 死ね ない ！ 」 と 強く 思い 、 「 生きよう と する 意思 」 に 目覚め た こと で 本当 の 強 さ を 手 に 入れ 、</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos 今年 は ジブリ が 輝い て い まし た 。 二 大 巨匠 の 宮崎駿 監督 と 高畑勲 監督 が 、 そろっ て 傑作 を 世に 出し た から でしょ う 。 さて 、 本作 、 物語 の 祖 と も 言わ れる 『 竹取物語 』 を モチーフ と し 、 展開 も ほぼ 原点 に 沿っ た もの と なっ て い ます 。 しかし 、 描か れ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos ターゲット の 夢 から 潜在意識 に 侵入 し 、 カタチ に なる 前 の アイデア を 盗み出す こと を 専門 と する 企業 スパイ 、 コブ （ ｌ ･ ディカプリオ ） は 、 業界 で も 屈指 の 凄腕 で ある 。 ある 事件 が 原因 で 最愛 の 妻 を 失い 、 その 殺人容疑 を かけ られ た 彼 は 、 祖国 に 二人 の 子供 を 残し</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos 私 が 思う ” 理想 的 な 悪人 俳優 ” は ショーン・ビーン と xxunk 、 そして xxunk です 。 という こと で 「 悪人 」 です 。 今作 は 「 パレード 」 で 知ら れる 吉田修一 さん の 原作 を 「 フラガール 」 や 「 69 」 を 手掛け た 李 監督 × 主演 に 妻夫木聡 さん × 音楽 を 久石譲 さん と 豪華 スタッフ ・ キャスト で 映像</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos 予告 トレーラー を 見 て ワクワク し つつ 、 反面 少し 不安 を 抱え ながら も 鑑賞 。 （ xxup 2d 字幕 ） しかし その 心配 は 杞憂 に 終わっ た ！ 本当に 素晴らしい 映画 だ ！ 新 世代 の 怪獣 xxup sf 映画 と 言える 快 作 （ 怪 作 ） だ 。 巨大 ロボ 「 イェーガー 」 は 無骨 で 重量感 たっぷり 、 まるで 巨大 な 重機</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Inr7kPswKAA"
   },
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder('ymr_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7TS0BSNwKAF",
    "outputId": "2ec91e71-f483-4245-b36c-615873bbafe0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 02:00 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.314499</td>\n",
       "      <td>0.251305</td>\n",
       "      <td>0.897328</td>\n",
       "      <td>02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJAXCZlSwKAH",
    "outputId": "26dda342-2958-424a-d548-b15d943233a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 02:14 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.271490</td>\n",
       "      <td>0.199659</td>\n",
       "      <td>0.923258</td>\n",
       "      <td>02:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PTdV7KbwKAI",
    "outputId": "737879f3-9f36-4996-f590-37040bdcbdae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 03:40 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.219154</td>\n",
       "      <td>0.183919</td>\n",
       "      <td>0.928497</td>\n",
       "      <td>03:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQrawItHwKAK",
    "outputId": "466392c1-1684-499f-857b-64f7d262f4c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 09:43 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.193065</td>\n",
       "      <td>0.181743</td>\n",
       "      <td>0.931116</td>\n",
       "      <td>04:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.180688</td>\n",
       "      <td>0.182315</td>\n",
       "      <td>0.931378</td>\n",
       "      <td>04:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDlz2N7NgWct"
   },
   "outputs": [],
   "source": [
    "learn.save('ymr_clas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfO83x3ywKAN",
    "outputId": "ab30f0e7-aa40-4a04-dbb8-50432b1b5a0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.0094, 0.9906]))"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"映画すごかったよ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJDz8-28wKAP",
    "outputId": "489dc15d-99cb-4de6-a164-69aa6c41405a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.9264, 0.0736]))"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"演技が悪い\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyZC6HMdwKBP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, 3e-3, moms=(0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmsVuYICgWea"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "LkXYHQhcwKAU",
    "b0_QNFnPwKBT"
   ],
   "include_colab_link": true,
   "name": "fastai-text-data-examples.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
