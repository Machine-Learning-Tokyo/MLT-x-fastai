{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of fastai-text-data-examples.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "LkXYHQhcwKAU",
        "b0_QNFnPwKBT"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Machine-Learning-Tokyo/MLT-x-fastai/blob/master/mini-lessons/fastai_text_data_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "i8F6rk1YwJ9P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "btS8qaALwJ9b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai import *\n",
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ZOWlQymwJ9g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Content from this notebook has been inspired from the fast.ai course-v3 Part 1. In this notebook we'll go through some standard NLP tasks using lessons from fast.ai. We will learn about Transfer Learning in NLP, creating `TextDataBunch` objects, training a model for text classification task, a Sequence2Sequence task and a Sequence Labeling task. We will see how the `fastai` library uses a style called the Data Block API to simplify the process of prepping data for different tasks."
      ]
    },
    {
      "metadata": {
        "id": "RAAKTmvMwJ9i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Google Colab notes: imports for uploading files\n",
        "#from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQMt1sO6wUHO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Google Colab notes: make data directory\n",
        "#!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FbtcGVLWwJ9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = Path('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "de1RHLVWwJ9t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Language Modeling\n",
        "\n",
        "One of the most common tasks done in NLP is called language modeling. A language model is an NLP model which learns to predict the next word in a sentence. We do this is because we assume that if a language model is quite accurate at guessing the next probable word in a sentnce, it needs a lot of world knowledge and a deep understanding of grammar, semantics, and other elements of natural language.\n",
        "\n",
        "We will show how to train a simple language model."
      ]
    },
    {
      "metadata": {
        "id": "562r2FPmwJ9u",
        "colab_type": "code",
        "outputId": "147d533d-32cc-4e59-b6e7-3c2949137bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
        "!mv nietzsche.txt data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-12 22:56:19--  https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.129.165\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.129.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 600901 (587K) [text/plain]\n",
            "Saving to: ‘nietzsche.txt’\n",
            "\n",
            "nietzsche.txt       100%[===================>] 586.82K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-04-12 22:57:23 (3.98 MB/s) - ‘nietzsche.txt’ saved [600901/600901]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TvqPqmt0wJ91",
        "colab_type": "code",
        "outputId": "23b97728-6ca4-4e29-b1ba-3b7c813cbcb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(open(path/'nietzsche.txt').read().split('\\n\\n'))\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PREFACE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nSUPPOSING that Truth is a woman--what then? ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sils Maria Upper Engadine, JUNE, 1885.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nCHAPTER I. PREJUDICES OF PHILOSOPHERS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0\n",
              "0                                            PREFACE\n",
              "1  \\nSUPPOSING that Truth is a woman--what then? ...\n",
              "2             Sils Maria Upper Engadine, JUNE, 1885.\n",
              "3                                                   \n",
              "4            \\nCHAPTER I. PREJUDICES OF PHILOSOPHERS"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "Z0LSpb-SwJ97",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bs=64\n",
        "data_lm = (TextList.from_df(df,path,cols=[0])\n",
        "                   .split_by_rand_pct(0.1)\n",
        "                   .label_for_lm()\n",
        "                   .databunch(bs=bs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JJf8PW9cwJ-A",
        "colab_type": "code",
        "outputId": "5ec5e34e-faca-4a35-af42-0b998aec5960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>unseemly methods for \\n  xxunk a woman ? xxmaj certainly she has never allowed herself to be won ; and \\n  at present every kind of dogma stands with sad and xxunk xxunk -- xxup if , \\n  indeed , it stands at all ! xxmaj for there are xxunk who maintain that it \\n  has fallen , that all dogma lies on the ground --</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>an opinion is life - xxunk , life - preserving , \\n  species - preserving , perhaps species - rearing , and we are fundamentally \\n  inclined to maintain that the xxunk opinions ( to which the synthetic \\n  judgments a priori belong ) , are the most indispensable to us , that \\n  without a recognition of logical fictions , without a comparison of \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>, the \\n  will to \" creation of the world , \" the will to the causa xxunk . xxbos 10 . xxmaj the eagerness and subtlety , i should even say craftiness , with \\n  which the problem of \" the real and the apparent world \" is xxunk with at \\n  present throughout xxmaj europe , furnishes food for thought and attention ; and \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>belief ought to be xxunk from science ! xxmaj between \\n  ourselves , it is not at all necessary to get rid of \" the soul \" thereby , \\n  and thus renounce one of the oldest and most xxunk hypotheses -- as \\n  happens frequently to the clumsiness of xxunk , who can hardly \\n  touch on the soul without immediately losing it . xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>alone is really known to us , absolutely and \\n  completely known , without deduction or addition . xxmaj but it again and \\n  again seems to me that in this case xxmaj schopenhauer also only did what \\n  philosophers are in the habit of doing -- he seems to have adopted a \\n  xxup popular xxup prejudice and exaggerated it . xxmaj willing seems to</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "VgctHNM_wJ-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM,drop_mult=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mKZQVe88wJ-S",
        "colab_type": "code",
        "outputId": "79059f27-394d-4a69-fc8d-c08d3d3f02d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiKDFAoiIjJIoSAiIoP+P50J1sOX+8uCAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "VH1Rrf2mwJ-a",
        "colab_type": "code",
        "outputId": "0debccd6-8716-4222-fab2-110bdc704210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(1,1e-2,moms=(0.7,0.8))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.749605</td>\n",
              "      <td>4.329587</td>\n",
              "      <td>0.213988</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lLQSsIHZwJ-h",
        "colab_type": "code",
        "outputId": "fea85c45-44ac-45d8-b8f5-1c631e0063bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(4,3e-3,moms=(0.7,0.8))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.242284</td>\n",
              "      <td>3.997777</td>\n",
              "      <td>0.256920</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.024162</td>\n",
              "      <td>3.899869</td>\n",
              "      <td>0.265625</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.843143</td>\n",
              "      <td>3.868506</td>\n",
              "      <td>0.266295</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.600221</td>\n",
              "      <td>3.874033</td>\n",
              "      <td>0.270610</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_Djk9URLwJ-m",
        "colab_type": "code",
        "outputId": "4e0f7e22-ca27-4d01-9ce9-3c60db7c2c28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "learn.predict('It is perhaps just dawning on five or six minds',n_words=100)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It is perhaps just dawning on five or six minds . Yet the most extensive fact of the \\n  circumstances has been been provided after the accident of More \\n  and Bell of Saint fire in whose grace and hatred of \\n  period talk represents their goal : where the populace has grown \\n  and there is well enough with regard to the HIGHER \\n  world of the present school , in whom a number could not , step home , be learnt \\n  to live as maid and lover and of distinction : \\n  hitherto , of course , in speaking hours and habits'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "uqQ2WuWKwJ-u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tokenization and Numericalization\n",
        "The most common preprocessing on NLP tasks in tokenization i.e splitting the sentence into words. This is much easier in space-seperated words like English however, for Japanese we require Morphological Analysis tools to get words from sentences.\n",
        "\n",
        "Numericalizing in the second preprocessing step. Since models can only take numbers as inputs, we make a dictionary mapping unique words to indices and replace the words with the words in the sentence with their corresponding index. Here we limit our dictionary size to 60000 words that appear at least twice in our corpus."
      ]
    },
    {
      "metadata": {
        "id": "nppsyhBqxQyT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Google Colab notes: install dependencies for mecab tokenizer\n",
        "#!sudo apt install swig\n",
        "#!sudo apt install mecab\n",
        "#!sudo apt install libmecab-dev\n",
        "#!sudo apt install mecab-ipadic-utf8\n",
        "#!sudo pip3 install mecab-python3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bZvJ9IAkxcGi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GZKaNpATwJ-u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import MeCab\n",
        "\n",
        "tagger = MeCab.Tagger(\"-Owakati\")\n",
        "\n",
        "class MeCabTokenizer(BaseTokenizer):\n",
        "    def __init__(self, lang:str):\n",
        "        self.lang = 'ja'\n",
        "    \n",
        "    def add_special_cases(self, toks:Collection[str]): pass\n",
        "    \n",
        "    def tokenizer(self,raw_sentence):\n",
        "        result = tagger.parse(raw_sentence)\n",
        "        words = result.split()\n",
        "        if len(words) == 0:\n",
        "            return []\n",
        "        if words[-1] == \"\\n\":\n",
        "            words = words[:-1]\n",
        "        return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5t-GgbaowJ_K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(MeCabTokenizer, 'ja')\n",
        "processor = [TokenizeProcessor(tokenizer=tokenizer), NumericalizeProcessor(max_vocab=60000,min_freq=2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T7BF02EpwJ-y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Text Classification\n",
        "One particular area that was challenging until recently with deep learning for NLP, was text classification.\n",
        "\n",
        "Similar to classifying images in text we can also use transfer learning to train accurate classifiers with few training examples. We will leverage weights from a language model trained on a large corpus as our pretrained weights. We will fine-tune the language model to our target dataset, attach a classification layer to our model and train by gradual unfreezing. The text classifying task will be sentiment analysis on Yahoo Movie Reviews. The data can be downloaded from this [repository](https://github.com/dennybritz/sentiment-analysis/tree/master/data)"
      ]
    },
    {
      "metadata": {
        "id": "1Ndi1UyJwJ-0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Google Colab Notes: download data and upload them into your notebook environment\n",
        "#files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "udgse3lozEiv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Google Colab Notes: uncompress data and move to data directory\n",
        "#!tar xvzf yahoo-movie-reviews.json.tar.gz\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "URd13SIGwJ-3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_ymr_data(path):\n",
        "    with path.open() as f:\n",
        "        data = pd.read_json(f)\n",
        "        data.movieName = data.movieName.str.strip()\n",
        "        data.text = data.text.str.strip()\n",
        "        data.title = data.title.str.strip()\n",
        "        data = data[data.text.str.len() > 0]\n",
        "        data.url = data.url.str.strip()\n",
        "    return data\n",
        "\n",
        "def make_polar(data, balance=True):\n",
        "    data_polar = data.loc[data.rating != 3].copy()\n",
        "    data_polar.loc[data_polar.rating <= 2, 'rating'] = 0\n",
        "    data_polar.loc[data_polar.rating >= 4, 'rating'] = 1\n",
        "    if balance:\n",
        "        # Subsample - We want the same number of positive and negative examples\n",
        "        grouped_ratings = data_polar.groupby('rating')\n",
        "        K = grouped_ratings.rating.count().min()\n",
        "        indices = itertools.chain(\n",
        "            *[np.random.choice(v, K, replace=False) for k, v in grouped_ratings.groups.items()])\n",
        "        data_polar = data_polar.reindex(indices).copy()\n",
        "    return data_polar\n",
        "\n",
        "\n",
        "mov_df = load_ymr_data(path/'yahoo-movie-reviews.json')\n",
        "mov_df_polar = make_polar(mov_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jTE7YgUwJ_A",
        "colab_type": "code",
        "outputId": "5028f518-38ae-42de-b319-44f57c04a054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "mov_df_polar.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>movieName</th>\n",
              "      <th>movieUrl</th>\n",
              "      <th>rating</th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49460</th>\n",
              "      <td>2007年5月19日 23時10分</td>\n",
              "      <td>パッチギ！　LOVE&amp;PEACE</td>\n",
              "      <td>http://movies.yahoo.co.jp/movie/%E3%83%91%E3%8...</td>\n",
              "      <td>0</td>\n",
              "      <td>頭どうかしているんでしょうね。\\n非常に差別的で嫌な気分になった。</td>\n",
              "      <td>差別的な描写が印象的な作品でした</td>\n",
              "      <td>http://movies.yahoo.co.jp/movie/%E3%83%91%E3%8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79552</th>\n",
              "      <td>2007年7月1日 23時57分</td>\n",
              "      <td>300 ＜スリーハンドレッド＞</td>\n",
              "      <td>http://movies.yahoo.co.jp/movie/300+%EF%BC%9C%...</td>\n",
              "      <td>0</td>\n",
              "      <td>この映画は，よくある，ハリウッドのアメリカ・プロパガンダ映画ではないか？という疑問が残った。...</td>\n",
              "      <td>この映画は・・？</td>\n",
              "      <td>http://movies.yahoo.co.jp/movie/300+%EF%BC%9C%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22569</th>\n",
              "      <td>2011年7月23日 20時41分</td>\n",
              "      <td>コクリコ坂から</td>\n",
              "      <td>http://movies.yahoo.co.jp/movie/%E3%82%B3%E3%8...</td>\n",
              "      <td>0</td>\n",
              "      <td>ストーリー自体は悪くはないと思いますが、\\nなぜ？いつの間に？という所が多々ありました。\\n...</td>\n",
              "      <td>置いてきぼりでした</td>\n",
              "      <td>http://movies.yahoo.co.jp/movie/%E3%82%B3%E3%8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72561</th>\n",
              "      <td>2010年9月10日 22時20分</td>\n",
              "      <td>第9地区</td>\n",
              "      <td>http://movies.yahoo.co.jp/movie/%E7%AC%AC9%E5%...</td>\n",
              "      <td>0</td>\n",
              "      <td>全然面白くないです。\\n第三者がビデオを取っていって、様々な人にインタビュー。それを繰り返し...</td>\n",
              "      <td>ショックです</td>\n",
              "      <td>http://movies.yahoo.co.jp/movie/%E7%AC%AC9%E5%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9719</th>\n",
              "      <td>2014年8月19日 20時54分</td>\n",
              "      <td>るろうに剣心</td>\n",
              "      <td>http://movies.yahoo.co.jp/movie/%E3%82%8B%E3%8...</td>\n",
              "      <td>0</td>\n",
              "      <td>無理やり戦わせようとする内容の上、先のストーリーが見えみえ。\\n\\n\\nカオルが戦いに子供ま...</td>\n",
              "      <td>1で期待したら残念な映画</td>\n",
              "      <td>http://movies.yahoo.co.jp/movie/%E3%82%8B%E3%8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    date         movieName  \\\n",
              "49460  2007年5月19日 23時10分  パッチギ！　LOVE&PEACE   \n",
              "79552   2007年7月1日 23時57分   300 ＜スリーハンドレッド＞   \n",
              "22569  2011年7月23日 20時41分           コクリコ坂から   \n",
              "72561  2010年9月10日 22時20分              第9地区   \n",
              "9719   2014年8月19日 20時54分            るろうに剣心   \n",
              "\n",
              "                                                movieUrl  rating  \\\n",
              "49460  http://movies.yahoo.co.jp/movie/%E3%83%91%E3%8...       0   \n",
              "79552  http://movies.yahoo.co.jp/movie/300+%EF%BC%9C%...       0   \n",
              "22569  http://movies.yahoo.co.jp/movie/%E3%82%B3%E3%8...       0   \n",
              "72561  http://movies.yahoo.co.jp/movie/%E7%AC%AC9%E5%...       0   \n",
              "9719   http://movies.yahoo.co.jp/movie/%E3%82%8B%E3%8...       0   \n",
              "\n",
              "                                                    text             title  \\\n",
              "49460                  頭どうかしているんでしょうね。\\n非常に差別的で嫌な気分になった。  差別的な描写が印象的な作品でした   \n",
              "79552  この映画は，よくある，ハリウッドのアメリカ・プロパガンダ映画ではないか？という疑問が残った。...          この映画は・・？   \n",
              "22569  ストーリー自体は悪くはないと思いますが、\\nなぜ？いつの間に？という所が多々ありました。\\n...         置いてきぼりでした   \n",
              "72561  全然面白くないです。\\n第三者がビデオを取っていって、様々な人にインタビュー。それを繰り返し...            ショックです   \n",
              "9719   無理やり戦わせようとする内容の上、先のストーリーが見えみえ。\\n\\n\\nカオルが戦いに子供ま...      1で期待したら残念な映画   \n",
              "\n",
              "                                                     url  \n",
              "49460  http://movies.yahoo.co.jp/movie/%E3%83%91%E3%8...  \n",
              "79552  http://movies.yahoo.co.jp/movie/300+%EF%BC%9C%...  \n",
              "22569  http://movies.yahoo.co.jp/movie/%E3%82%B3%E3%8...  \n",
              "72561  http://movies.yahoo.co.jp/movie/%E7%AC%AC9%E5%...  \n",
              "9719   http://movies.yahoo.co.jp/movie/%E3%82%8B%E3%8...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "1zXLt6RmwJ_R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bs=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BjtxfW2RwJ_Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_lm = (TextList.from_df(mov_df_polar,path,cols=['text'],processor=processor)\n",
        "                   .split_by_rand_pct(0.1)\n",
        "                   .label_for_lm()\n",
        "                   .databunch(bs=bs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8VFZlZJRwJ_g",
        "colab_type": "code",
        "outputId": "8403edce-33d6-41b3-be0d-c62912449e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>， 命がけ で “ 自由 の ため ” に 戦う ， 孤高 の 王 。 “ 野蛮 で 封建 的 な アジア の xxunk ” 率いる 化け物 じみ た 大軍 を ， 気持ちよく ばった ばった と なぎ倒し ， 最後 に は 犠牲 と なり 華々しく 死ん で いき ， 英雄 として 語り継が れ ， 人々 を 奮い立た せる 。 映像 は 残酷 だ が かっこよく ， 現代 の 鬱屈 し</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>いる と しか 受け取れ ませ ん 。 それ を 、 在日 の 人 たち に 言わ せ て いる ところ が 反感 を 買う 原因 です よ ね 。 相手 を 傷つけ ない と 自分 の 哀しみ を 表せ ない の でしょ う か ？ 相手 を 倒さ ない と 自分 の 主張 を 伝え られ ない の でしょ う か ？ 差別 と 常に 戦っ て いる 在日 の</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>だ と 思い ます 。 世界 に 入り込めれ ば 大丈夫 でしょ う 。 ちなみに 私 は 2 ｄ で 十分 でし た 。 アバター を 3 ｄ で 観 た 時 、 何だか 映像 に 酔っ て しまっ て 気分 が 悪かっ た ので 、 アリス は 2 ｄ を 選択 し まし た が 、 やっぱり 正解 でし た 。 とても カラフル な 世界 観 の お話 な ので</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>、 どんな 理由 が あろ う と 自分 を 育て て くれ なかっ た xxunk も ある と 思い ます 。 そして 養母 という の は 愛さ なけれ ば なら ない けれど 、 本音 として は 自分 の 愛する 母 に 取っ て xxunk う と する 不遜 な 輩 な ん です 。 しかし 、 育て て もらえ ば 情 も 沸く し 、 思慕 が 生まれ ます 、</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>。 xxbos 無駄 でし た 。 面白く ない と いう より 、 浅く て 観る の が 辛い 。 これ だけ 中身 の ない もの だ と は 思わ なかっ た 。 xxbos ﾋﾞｯｸﾘ し まし た ねぇ ～。 海 猿 は 、 xxup sf だっ た ん です ねぇ 。 あん だけ 傾い てる 船 の 船内 で 、 当たり前 の よう に 、 真っ直ぐ 立っ て 歩く 一同</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_83e7pMewJ_l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will initialize our model with weights from a language model trained on Japanese Wikipedia. You can download them from [here](https://drive.google.com/open?id=1KRUEV_3R-JVhcftvWJ66rwU7e_EZWtxE) and you need to place the files in the `data/models/` directory"
      ]
    },
    {
      "metadata": {
        "id": "axYJrS2jwJ_l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Google colab notes: upload model files\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#!cp /content/drive/My\\ Drive/ja-wiki-awdlstm-model/ja-wiki-itos.pkl \n",
        "#!cp /content/drive/My\\ Drive/ja-wiki-awdlstm-model/ja-wiki.pth ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gKzpoyBl8aZi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!mv ja-wiki-itos.pkl data/models\n",
        "#!mv ja-wiki.pth data/models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EDROqQ_xwJ_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM,pretrained_fnames=['ja-wiki','ja-wiki-itos'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "8t935fGjwJ_p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(1,1e-2,moms=(0.7,0.8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "85HGj4ATwJ_w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(10,3e-3,moms=(0.7,0.8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x2kbsexYwJ_3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('ymr')\n",
        "learn.save_encoder('ymr_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FarNDkEYwJ_7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_clas = (TextList.from_df(mov_df_polar,path,cols=['text'],vocab=data_lm.vocab,processor=processor)\n",
        "                   .split_by_rand_pct(0.1)\n",
        "                   .label_from_df(cols=['rating'])\n",
        "                   .databunch(bs=bs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a0F0IN2LwJ_9",
        "colab_type": "code",
        "outputId": "20f1aebe-decc-4669-c64e-7dbed3d83285",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos ・ 過去 の 行い と 罪 の 意識 から 強 さ の 裏 で 自分 の 命 を 軽 ん じ て い た 剣心 が 、 師匠 と 剣 を 交える うち に 「 死に たく ない ！ 」 「 死ね ない ！ 」 と 強く 思い 、 「 生きよう と する 意思 」 に 目覚め た こと で 本当 の 強 さ を 手 に 入れ 、</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos 率直 に 、 素直 に ・ ・ この 映画 、 不快 でし た ・ ・ 。 それ と共に 、 友人 から 聞い た 日本人差別 の 話 が 、 頭 に 甦り まし た 。 幼稚園 の xxunk の とき から の 、 xxunk が 、 xxunk の 時 、 お 父様 の 転勤 で 、 アメリカ xxup la に 、 xxunk し まし た 。 その 友人 と は</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos 「 パッチギ xxup love＆peace 」 で は 、 「 在日 は 被害者 、 日本人 は 悪者 」 という 構図 で 話 が 描か れ て い ます 。 では 、 はたして 実際 にそう だっ た の でしょ う か ？ 現在 の 朝鮮総連 の xxunk 団体 で ある 「 xxunk 」 xxunk は １ ９ ４ ６ 年 初頭 に 「 日本 の 敗戦 で 開放 さ れ た</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos 私 は 、 「 ガンダム 」 や 、 「 エヴァンゲリオン 」 等 は 、 タイトル を 知っ て いる くらい で 、 ほとんど 、 観 た 事 が ありません な ので 、 初めて 、 本作 の 「 予告 」 を 観 た 時 も 、 鼻 で 笑っ て い まし た 。 &lt;(_ _)&gt; よって 、 その 時点 で は 、 当然 、 xxunk つもり で い た</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos マーティン・スコセッシ 監督 、 レオナルド・ディカプリオ 主演 の 謎解き ミステリー 。 しかし 、 また し て も 宣伝 は 、 作品 本来 の 魅力 で は なく 、 表面 上 の ミステリー 部分 を xxup ｐｒ し て いる よう で 、 納得 でき ない ところ が あり ます 。 この 作品 は 、 伏線 の 多い ミステリー だ から こそ 、 画面 に 集中 し て もらう ため 、 そして</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3Inr7kPswKAA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
        "learn.load_encoder('ymr_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P7TS0BSNwKAF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RJAXCZlSwKAH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6PTdV7KbwKAI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gQrawItHwKAK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gfO83x3ywKAN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.predict(\"映画すごかったよ!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jJDz8-28wKAP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.predict(\"演技が悪い\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LkXYHQhcwKAU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Seq2Seq\n",
        "\n",
        "A sequence-to-sequence model is a model that takes a sequence of items and outputs another sequence of items using two networks that are trained end-to-end. This is perfect for machine translation since input sequences are directly related to output sequences. We will looking at preparing a dataset for Machine Translation task and implementing a seq2seq model. We will be using the parallel corpus available from [here](ftp://ftp.monash.edu/pub/nihongo/examples.utf.gz)"
      ]
    },
    {
      "metadata": {
        "id": "I5KcBSgDwKAU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_corpus(corpus_path):\n",
        "    corpus = corpus_path.open().readlines()\n",
        "    data_pair = []\n",
        "    pat = r'#ID.+\\n'\n",
        "    for c in corpus:\n",
        "        if 'A: ' in c:\n",
        "            clean_c = c.replace('A: ','')\n",
        "            res = re.search(pat,clean_c)\n",
        "            clean_c = clean_c.replace(res.group(0),'').split('\\t')\n",
        "            data_pair.append((clean_c[0],clean_c[1]))\n",
        "    return pd.DataFrame(data_pair,columns=['ja','en'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LBvnts3UwKAY",
        "colab_type": "code",
        "outputId": "82c45ceb-1eae-44e3-e742-0d0ca8e2fb65",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = make_corpus(path/'examples.utf')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ja</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ムーリエルは２０歳になりました。</td>\n",
              "      <td>Muiriel is 20 now.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>すぐに戻ります。</td>\n",
              "      <td>I will be back soon.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>すぐに諦めて昼寝をするかも知れない。</td>\n",
              "      <td>I may give up soon and just nap instead.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>愛してる。</td>\n",
              "      <td>I love you.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ログアウトするんじゃなかったよ。</td>\n",
              "      <td>I shouldn't have logged off.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   ja                                        en\n",
              "0    ムーリエルは２０歳になりました。                        Muiriel is 20 now.\n",
              "1            すぐに戻ります。                      I will be back soon.\n",
              "2  すぐに諦めて昼寝をするかも知れない。  I may give up soon and just nap instead.\n",
              "3               愛してる。                               I love you.\n",
              "4    ログアウトするんじゃなかったよ。              I shouldn't have logged off."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "3Kvee5X9wKAa",
        "colab_type": "code",
        "outputId": "3890af75-7119-4f9d-bccf-0d1c27a442e1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "x9PxAEtXwKAd",
        "colab_type": "code",
        "outputId": "e75f4df0-9e53-4bbd-fc86-daf64ff6a1c1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_idxs = np.random.choice(np.arange(len(df)), int(0.1*len(df)),replace=False)\n",
        "train_idxs = [i for i in np.arange(len(df)) if i not in valid_idxs]\n",
        "len(train_idxs) + len(valid_idxs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "metadata": {
        "id": "u1UYkzBUwKAg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#collation function and databunch code borrowed from here: \n",
        "#https://github.com/ohmeow/seq2seq-pytorch-fastai/blob/master/seq2seq-rnn-attn.ipynb\n",
        "\n",
        "def seq2seq_pad_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=False, \n",
        "                        include_targets=True, include_lengths=False, include_masks=False,\n",
        "                        backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
        "    \n",
        "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
        "    \n",
        "    samples = to_data(samples)\n",
        "    samples.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "    \n",
        "    x_lens = [len(s[0]) for s in samples]\n",
        "    x_max_len = max(x_lens)\n",
        "    x_res = torch.zeros(len(samples), x_max_len).long() + pad_idx\n",
        "    \n",
        "    y_lens = [len(s[1]) for s in samples]\n",
        "    y_max_len = max(y_lens)\n",
        "    y_res = torch.zeros(len(samples), y_max_len).long() + pad_idx\n",
        "    \n",
        "    if backwards: pad_first = not pad_first\n",
        "        \n",
        "    for i,s in enumerate(samples):\n",
        "        if pad_first: \n",
        "            x_res[i,-len(s[0]):] = LongTensor(s[0])\n",
        "            y_res[i,-len(s[1]):] = LongTensor(s[1])\n",
        "        else:         \n",
        "            x_res[i,:len(s[0]):] = LongTensor(s[0])\n",
        "            y_res[i,:len(s[1]):] = LongTensor(s[1])\n",
        "            \n",
        "    if backwards: res = res.flip(1)\n",
        "        \n",
        "    x = [x_res]\n",
        "    if (include_targets): x += [y_res.clone()]\n",
        "    if (include_lengths): x += [torch.tensor(x_lens), torch.tensor(y_lens)]\n",
        "    if (include_masks): x += [x_res != pad_idx, y_res != pad_idx]\n",
        "    \n",
        "    return x, y_res\n",
        "\n",
        "\n",
        "class Seq2SeqDataBunch(DataBunch):\n",
        "\n",
        "    @classmethod\n",
        "    def create(cls, train_ds, valid_ds, test_ds=None, \n",
        "               path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1, pad_first=False, \n",
        "               device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
        "        \n",
        "        \"\"\"Function that transform the `datasets` in a `DataBunch` for seq2seq task. \n",
        "        Passes `**dl_kwargs` on to `DataLoader()`\"\"\"\n",
        "        \n",
        "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
        "        val_bs = ifnone(val_bs, bs)\n",
        "        \n",
        "        collate_fn = partial(seq2seq_pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
        "        \n",
        "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
        "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
        "        \n",
        "        dataloaders = [train_dl]\n",
        "        for ds in datasets[1:]:\n",
        "            lengths = [len(t) for t in ds.x.items]\n",
        "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
        "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
        "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o9_Q7LXJwKAi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Seq2SeqTextList(TextList):\n",
        "    _bunch = Seq2SeqDataBunch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FpOxgbMTwKAk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "en_tok = Tokenizer(lang='en')\n",
        "en_procs = [TokenizeProcessor(tokenizer=en_tok, include_bos=True, include_eos=True), \n",
        "            NumericalizeProcessor(min_freq=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jo-p4T_pwKAm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(MeCabTokenizer, 'ja')\n",
        "ja_procs = [TokenizeProcessor(tokenizer=tokenizer,include_bos=True, include_eos=True), NumericalizeProcessor(max_vocab=30000,min_freq=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k3WuE-cawKAn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "en_il = Seq2SeqTextList.from_df(df, path, cols=['en'], processor=en_procs).process().split_by_idxs(train_idxs,valid_idxs)\n",
        "ja_il = Seq2SeqTextList.from_df(df, path, cols=['ja'], processor=ja_procs).process().split_by_idxs(train_idxs,valid_idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lp77piH5wKAp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tr_ll = LabelList(en_il.train,ja_il.train)\n",
        "val_ll = LabelList(en_il.valid,ja_il.valid)\n",
        "lls = LabelLists(path,train=tr_ll,valid=val_ll)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4HU6eew3wKAr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq2seq_data = lls.databunch(bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cgDqNCjywKAs",
        "colab_type": "code",
        "outputId": "38610cfa-b5cc-4ad0-9d41-dd8896cba213",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq2seq_data.train_ds[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos xxmaj muiriel is 20 now . xxeos,\n",
              " Text xxbos ムーリエル は ２ ０ 歳 に なり まし た 。 xxeos)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "metadata": {
        "id": "XejAD33ZwKAu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "en_vecs,_,dim_en_vec = load_vectors('data/wiki-news-300d-1M.vec')\n",
        "j_vecs,_,dim_j_vec = load_vectors('data/cc.ja.300.vec')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pydn2l1bwKAw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_emb(vecs, itos, em_sz):\n",
        "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
        "    if vecs is None: return emb\n",
        "    wgts = emb.weight.data\n",
        "    miss = []\n",
        "    for i,w in enumerate(itos):\n",
        "        try: wgts[i] = torch.from_numpy(vecs[w])\n",
        "        except: miss.append(w)\n",
        "    print('Number of unknowns in data: {}'.format(len(miss)))\n",
        "    return emb\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F1roMu9AwKAx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
        "def rand_p(*sz): return nn.Parameter(rand_t(*sz))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HCIfiPkVwKA2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Seq2SeqAttention(nn.Module):\n",
        "    def __init__(self,int2en,int2j,em_sz,j_vecs=None,en_vecs=None,nh=128,out_sl=25,dropf=1,nl=2):\n",
        "        super().__init__()\n",
        "        #encoder\n",
        "        self.nl,self.nh,self.em_sz,self.out_sl = nl,nh,em_sz,out_sl\n",
        "        self.emb_enc = create_emb(en_vecs,int2en,em_sz)\n",
        "        self.emb_drop = nn.Dropout(0.15*dropf)\n",
        "        self.encoder = nn.GRU(em_sz,nh,num_layers=nl,dropout=0.25*dropf, bidirectional=True,batch_first=True)\n",
        "        #decoder\n",
        "        self.emb_dec = create_emb(j_vecs,int2j,em_sz)\n",
        "        self.decoder = nn.GRU(em_sz,nh*2,num_layers=nl,dropout=0.25*dropf,batch_first=True)\n",
        "        self.out_drop = nn.Dropout(0.35*dropf)\n",
        "        self.out = nn.Linear(nh*2,len(int2j))\n",
        "        #attention layer\n",
        "        self.W1 = rand_p(nh*2, nh*2) #parameter\n",
        "        self.l2 = nn.Linear(nh*2, nh*2)\n",
        "        self.l3 = nn.Linear(em_sz+nh*2, em_sz)\n",
        "        self.V = rand_p(nh*2) #parameter\n",
        "        self.targets = None\n",
        "    \n",
        "    def forward(self,inp,y=None):\n",
        "        self.targets = y\n",
        "        bs,sl = inp.size()\n",
        "        emb_in = self.emb_drop(self.emb_enc(inp))\n",
        "        h_n = self.initHidden(bs)\n",
        "        enc_out, h_n = self.encoder(emb_in,h_n)\n",
        "        h_n = h_n.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
        "        \n",
        "        dec_inp = torch.zeros(bs).long().cuda()\n",
        "        res,attns = [], []\n",
        "        #multiply by parameter\n",
        "        w1e = enc_out @ self.W1\n",
        "        for i in range(self.out_sl):\n",
        "            #linear layer \n",
        "            w2h = self.l2(h_n[-1])\n",
        "            #non-linear activation to calculate score\n",
        "            u = torch.tanh(w1e + w2h.unsqueeze(1))\n",
        "            #softmax to make them into probs\n",
        "            a = F.softmax(u @ self.V, 0)\n",
        "            attns.append(a)\n",
        "            #multiply each vector by scores and then add them up\n",
        "            Xa = (a.unsqueeze(2) * enc_out).sum(1)\n",
        "            dec_emb = self.emb_dec(dec_inp)\n",
        "            #linear layer to reduce dimensions\n",
        "            wgt_enc = self.l3(torch.cat([dec_emb, Xa], 1))\n",
        "            outp,h_n = self.decoder(wgt_enc.unsqueeze(1),h_n)\n",
        "            outp = self.out(self.out_drop(outp[:,0]))\n",
        "            res.append(outp)\n",
        "            dec_inp = outp.data.max(1)[1]\n",
        "            if i >=self.targets.size(1):break\n",
        "            if (dec_inp==1).all(): break\n",
        "            if (random.random() > 0.5) and self.targets is not None: dec_inp=y[:,i] \n",
        "        return torch.stack(res).transpose(1,0)\n",
        "        \n",
        "    def initHidden(self,bs):\n",
        "        return torch.zeros([self.nl*2,bs,self.nh]).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tgE3MgKewKA4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def seq2seq_loss(input, target):\n",
        "    bs,sl = target.size()\n",
        "    bs_in,sl_in,nc = input.size()\n",
        "    if sl>sl_in: input = F.pad(input, (0,0,0,sl-sl_in,0,0))\n",
        "    input = input[:,:sl,:]\n",
        "    return F.cross_entropy(input.contiguous().view(-1,nc), target.contiguous().view(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eFmsFBajwKA6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TeacherForcingCallback(LearnerCallback):\n",
        "    learn:Learner\n",
        "        \n",
        "    def on_batch_begin(self, train, **kwargs):\n",
        "        learn.model.targets = kwargs['last_target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tkG597I4wKA9",
        "colab_type": "code",
        "outputId": "3ef8c0a6-3dc7-4e61-eb65-6cdf9bb13279",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq2seq = Seq2SeqAttention(seq2seq_data.train_ds.x.vocab.itos,seq2seq_data.train_ds.y.vocab.itos,300,en_vecs=None,j_vecs=None)\n",
        "seq2seq.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqAttention(\n",
              "  (emb_enc): Embedding(21395, 300, padding_idx=1)\n",
              "  (emb_drop): Dropout(p=0.15)\n",
              "  (encoder): GRU(300, 128, num_layers=2, batch_first=True, dropout=0.25, bidirectional=True)\n",
              "  (emb_dec): Embedding(30004, 300, padding_idx=1)\n",
              "  (decoder): GRU(300, 256, num_layers=2, batch_first=True, dropout=0.25)\n",
              "  (out_drop): Dropout(p=0.35)\n",
              "  (out): Linear(in_features=256, out_features=30004, bias=True)\n",
              "  (l2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (l3): Linear(in_features=556, out_features=300, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 295
        }
      ]
    },
    {
      "metadata": {
        "id": "0tco_NyzwKBA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = Learner(seq2seq_data,seq2seq)\n",
        "learn.loss_func = seq2seq_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Pt8Oc0awKBD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.callbacks.append(TeacherForcingCallback(learn))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pwqdx2n7wKBH",
        "colab_type": "code",
        "outputId": "8e357689-3322-40af-c1a9-b3914fbab3f3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lCzEk-vPwKBK",
        "colab_type": "code",
        "outputId": "03288ac5-1813-4a03-e6f7-4610ccfb2bf4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "xyZC6HMdwKBP",
        "colab_type": "code",
        "outputId": "e04024bf-f3f0-48e4-aef6-0bd10d6f9bd4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(5, 3e-3, moms=(0.7,0.8))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      40.00% [2/5 07:40<11:31]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.339883</td>\n",
              "      <td>2.918007</td>\n",
              "      <td>03:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.839581</td>\n",
              "      <td>2.631924</td>\n",
              "      <td>03:53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='2106', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-298-8d451ab2bd28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-292-55a6db7275b7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, y)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mwgt_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdec_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXa\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0moutp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwgt_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mdec_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "b0_QNFnPwKBT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sequence Labeling"
      ]
    },
    {
      "metadata": {
        "id": "OG76M9B0wKBU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}