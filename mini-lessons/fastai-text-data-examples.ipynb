{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content from this notebook has been inspired from the fast.ai course-v3 Part 1. In this notebook we'll go through some standard NLP tasks using lessons from fast.ai. We will learn about Transfer Learning in NLP, creating `TextDataBunch` objects, training a model for text classification task, a Sequence2Sequence task and a Sequence Labeling task. We will see how the `fastai` library uses a style called the Data Block API to simplify the process of prepping data for different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google Colab notes: imports for uploading files\n",
    "#from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Modeling\n",
    "\n",
    "One of the most common tasks done in NLP is called language modeling. A language model is an NLP model which learns to predict the next word in a sentence. We do this is because we assume that if a language model is quite accurate at guessing the next probable word in a sentnce, it needs a lot of world knowledge and a deep understanding of grammar, semantics, and other elements of natural language.\n",
    "\n",
    "We will show how to train a simple language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-12 08:23:33--  https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.163.77\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.163.77|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 600901 (587K) [text/plain]\n",
      "Saving to: ‘nietzsche.txt’\n",
      "\n",
      "nietzsche.txt       100%[===================>] 586.82K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2019-04-12 08:23:34 (21.8 MB/s) - ‘nietzsche.txt’ saved [600901/600901]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
    "!mv nietzsche.txt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PREFACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUPPOSING that Truth is a woman--what then? Is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for suspecting that all philosophers, in so fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                                            PREFACE\n",
       "1                                                   \n",
       "2                                                   \n",
       "3  SUPPOSING that Truth is a woman--what then? Is...\n",
       "4  for suspecting that all philosophers, in so fa..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(open(path/'nietzsche.txt').read().split('\\n'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = (TextList.from_df(df,path,cols=[0])\n",
    "                   .split_by_rand_pct(0.1)\n",
    "                   .label_for_lm()\n",
    "                   .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xxunk methods for \\n  xxunk a woman ? xxmaj certainly she has never allowed herself to be won ; and \\n  at present every kind of dogma stands with sad and xxunk xxunk -- xxup if , \\n  indeed , it stands at all ! xxmaj for there are xxunk who maintain that it \\n  has fallen , that all dogma lies on the ground --</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>. xxmaj having kept a sharp eye on philosophers , and having read between \\n  their lines long enough , i now say to myself that the greater part of \\n  conscious thinking must be xxunk among the instinctive functions , and \\n  it is so even in the case of philosophical thinking ; one has here to \\n  learn anew , as one learned anew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>nature , \" means \\n  actually the same as \" living according to xxunk could you do \\n  xxup differently ? xxmaj why should you make a principle out of what you yourselves \\n  are , and must be ? xxmaj in reality , however , it is quite otherwise with you : \\n  while you xxunk to read with xxunk the xxunk of your law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>to \\n  xxmaj german philosophy , it was a delight to the noble xxunk , the virtuous , \\n  the xxunk , the xxunk , the three - fourths xxmaj christians , and the \\n  political xxunk of all nations , to find an antidote to the still \\n  xxunk sensualism which xxunk from the last century into \\n  this , in xxunk xxunk .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>a \\n  xxup popular xxup prejudice and exaggerated it . xxmaj willing seems to me to be above \\n  all something xxup complicated , something that is a unity only in name -- and \\n  it is precisely in a name that popular prejudice lurks , which has got \\n  the mastery over the xxunk xxunk of philosophers in all ages . \\n  xxmaj so</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM,drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:02 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.739930</td>\n",
       "      <td>4.243732</td>\n",
       "      <td>0.219531</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1,1e-2,moms=(0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:12 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.246180</td>\n",
       "      <td>3.930275</td>\n",
       "      <td>0.253069</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.047166</td>\n",
       "      <td>3.802835</td>\n",
       "      <td>0.278850</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.777944</td>\n",
       "      <td>3.773712</td>\n",
       "      <td>0.287556</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.528073</td>\n",
       "      <td>3.786354</td>\n",
       "      <td>0.288170</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4,3e-3,moms=(0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is perhaps just dawning on five or six minds that a faculty of philosophy might \\n  be responsible for its development . Even in its most logical position , no \\n  goal , no doubt , would always be necessary for the very preservation and very maintenance of \\n  itself , depends upon all the general utility , and \\n  should be taught to do so . As \\n  far as we look upon we obtain , we find it difficult when we learn , are just \\n  eager to APPROACH OUR ANTAGONISM are REALLY \\n  better -- we want the English'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('It is perhaps just dawning on five or six minds',n_words=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Numericalization\n",
    "The most common preprocessing on NLP tasks in tokenization i.e splitting the sentence into words. This is much easier in space-seperated words like English however, for Japanese we require Morphological Analysis tools to get words from sentences.\n",
    "\n",
    "Numericalizing in the second preprocessing step. Since models can only take numbers as inputs, we make a dictionary mapping unique words to indices and replace the words with the words in the sentence with their corresponding index. Here we limit our dictionary size to 60000 words that appear at least 3 times in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import MeCab\n",
    "\n",
    "tagger = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "class MeCabTokenizer(BaseTokenizer):\n",
    "    def __init__(self, lang:str):\n",
    "        self.lang = 'ja'\n",
    "    \n",
    "    def add_special_cases(self, toks:Collection[str]): pass\n",
    "    \n",
    "    def tokenizer(self,raw_sentence):\n",
    "        result = tagger.parse(raw_sentence)\n",
    "        words = result.split()\n",
    "        if len(words) == 0:\n",
    "            return []\n",
    "        if words[-1] == \"\\n\":\n",
    "            words = words[:-1]\n",
    "        return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "One particular area that was challenging until recently with deep learning for NLP, was text classification.\n",
    "\n",
    "Similar to classifying images in text we can also use transfer learning to train accurate classifiers with few training examples. We will leverage weights from a language model trained on a large corpus as our pretrained weights. We will fine-tune the language model to our target dataset, attach a classification layer to our model and train by gradual unfreezing. The text classifying task will be sentiment analysis on Yahoo Movie Reviews. The data can be downloaded from this [repository](https://github.com/dennybritz/sentiment-analysis/tree/master/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google Colab Notes: download data and upload them into your notebook environment\n",
    "#files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ymr_data(path):\n",
    "    with path.open() as f:\n",
    "        data = pd.read_json(f)\n",
    "        data.movieName = data.movieName.str.strip()\n",
    "        data.text = data.text.str.strip()\n",
    "        data.title = data.title.str.strip()\n",
    "        data = data[data.text.str.len() > 0]\n",
    "        data.url = data.url.str.strip()\n",
    "    return data\n",
    "\n",
    "def make_polar(data, balance=True):\n",
    "    data_polar = data.loc[data.rating != 3].copy()\n",
    "    data_polar.loc[data_polar.rating <= 2, 'rating'] = 0\n",
    "    data_polar.loc[data_polar.rating >= 4, 'rating'] = 1\n",
    "    if balance:\n",
    "        # Subsample - We want the same number of positive and negative examples\n",
    "        grouped_ratings = data_polar.groupby('rating')\n",
    "        K = grouped_ratings.rating.count().min()\n",
    "        indices = itertools.chain(\n",
    "            *[np.random.choice(v, K, replace=False) for k, v in grouped_ratings.groups.items()])\n",
    "        data_polar = data_polar.reindex(indices).copy()\n",
    "    return data_polar\n",
    "\n",
    "\n",
    "mov_df = load_ymr_data(path/'yahoo-movie-reviews.json')\n",
    "mov_df_polar = make_polar(mov_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>movieName</th>\n",
       "      <th>movieUrl</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85996</th>\n",
       "      <td>2014年8月25日 13時06分</td>\n",
       "      <td>GODZILLA　ゴジラ</td>\n",
       "      <td>http://movies.yahoo.co.jp/movie/GODZILLA%E3%80...</td>\n",
       "      <td>0</td>\n",
       "      <td>結論。\\nゴジラが出れば、何とかなる的なおそまつなストリー展開。\\nオープニングは何となくわ...</td>\n",
       "      <td>がっかり。</td>\n",
       "      <td>http://movies.yahoo.co.jp/movie/GODZILLA%E3%80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43189</th>\n",
       "      <td>2007年5月5日 21時38分</td>\n",
       "      <td>バベル</td>\n",
       "      <td>http://movies.yahoo.co.jp/movie/%E3%83%90%E3%8...</td>\n",
       "      <td>0</td>\n",
       "      <td>映画自体の内容よりも、ブラピとRINKO KIKUCHIが日本では話題になっていただけの映画...</td>\n",
       "      <td>はっきり言って駄作・・・</td>\n",
       "      <td>http://movies.yahoo.co.jp/movie/%E3%83%90%E3%8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66294</th>\n",
       "      <td>2015年10月29日 22時16分</td>\n",
       "      <td>心が叫びたがってるんだ。</td>\n",
       "      <td>http://movies.yahoo.co.jp/movie/%E5%BF%83%E3%8...</td>\n",
       "      <td>0</td>\n",
       "      <td>開始5分でこれダメだと思った。とってつけたような安い恋愛模様、酷い下ネタ、歌で誤魔化してる感...</td>\n",
       "      <td>予告と違う</td>\n",
       "      <td>http://movies.yahoo.co.jp/movie/%E5%BF%83%E3%8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42707</th>\n",
       "      <td>2007年8月10日 15時16分</td>\n",
       "      <td>トランスフォーマー</td>\n",
       "      <td>http://movies.yahoo.co.jp/movie/%E3%83%88%E3%8...</td>\n",
       "      <td>0</td>\n",
       "      <td>ロボット達の変形、戦闘かなり良かったんだけどどうもデザインがいただけない、現代のアメコミ風と...</td>\n",
       "      <td>CGは最高点　だけどね・・・不満いっぱい</td>\n",
       "      <td>http://movies.yahoo.co.jp/movie/%E3%83%88%E3%8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21297</th>\n",
       "      <td>2011年9月14日 16時29分</td>\n",
       "      <td>コクリコ坂から</td>\n",
       "      <td>http://movies.yahoo.co.jp/movie/%E3%82%B3%E3%8...</td>\n",
       "      <td>0</td>\n",
       "      <td>タイトルとの関連って、気になりますよね。。\\n\\nでも坂が関係したのは、カレーの肉を買いに駿...</td>\n",
       "      <td>ようやく見てきましたが</td>\n",
       "      <td>http://movies.yahoo.co.jp/movie/%E3%82%B3%E3%8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date     movieName  \\\n",
       "85996   2014年8月25日 13時06分  GODZILLA　ゴジラ   \n",
       "43189    2007年5月5日 21時38分           バベル   \n",
       "66294  2015年10月29日 22時16分  心が叫びたがってるんだ。   \n",
       "42707   2007年8月10日 15時16分     トランスフォーマー   \n",
       "21297   2011年9月14日 16時29分       コクリコ坂から   \n",
       "\n",
       "                                                movieUrl  rating  \\\n",
       "85996  http://movies.yahoo.co.jp/movie/GODZILLA%E3%80...       0   \n",
       "43189  http://movies.yahoo.co.jp/movie/%E3%83%90%E3%8...       0   \n",
       "66294  http://movies.yahoo.co.jp/movie/%E5%BF%83%E3%8...       0   \n",
       "42707  http://movies.yahoo.co.jp/movie/%E3%83%88%E3%8...       0   \n",
       "21297  http://movies.yahoo.co.jp/movie/%E3%82%B3%E3%8...       0   \n",
       "\n",
       "                                                    text  \\\n",
       "85996  結論。\\nゴジラが出れば、何とかなる的なおそまつなストリー展開。\\nオープニングは何となくわ...   \n",
       "43189  映画自体の内容よりも、ブラピとRINKO KIKUCHIが日本では話題になっていただけの映画...   \n",
       "66294  開始5分でこれダメだと思った。とってつけたような安い恋愛模様、酷い下ネタ、歌で誤魔化してる感...   \n",
       "42707  ロボット達の変形、戦闘かなり良かったんだけどどうもデザインがいただけない、現代のアメコミ風と...   \n",
       "21297  タイトルとの関連って、気になりますよね。。\\n\\nでも坂が関係したのは、カレーの肉を買いに駿...   \n",
       "\n",
       "                      title                                                url  \n",
       "85996                 がっかり。  http://movies.yahoo.co.jp/movie/GODZILLA%E3%80...  \n",
       "43189          はっきり言って駄作・・・  http://movies.yahoo.co.jp/movie/%E3%83%90%E3%8...  \n",
       "66294                 予告と違う  http://movies.yahoo.co.jp/movie/%E5%BF%83%E3%8...  \n",
       "42707  CGは最高点　だけどね・・・不満いっぱい  http://movies.yahoo.co.jp/movie/%E3%83%88%E3%8...  \n",
       "21297           ようやく見てきましたが  http://movies.yahoo.co.jp/movie/%E3%82%B3%E3%8...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov_df_polar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(MeCabTokenizer, 'ja')\n",
    "processor = [TokenizeProcessor(tokenizer=tokenizer), NumericalizeProcessor(max_vocab=60000,min_freq=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = (TextList.from_df(mov_df_polar,path,cols=['text'],processor=processor)\n",
    "                   .split_by_rand_pct(0.1)\n",
    "                   .label_for_lm()\n",
    "                   .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>、 気合い 入れ て 臨ん だ に も 拘ら ず 筋 の 無い 映画 に がっかり だっ た の で は ？ xxbos 映画 自体 の 内容 より も 、 ブラピ と xxup xxunk xxup xxunk が 日本 で は 話題 に なっ て い た だけ の 映画 でし た 。 観 て い て 不快感 と 沈ん だ 気持ち が 残る し 、 映画 に ぐいぐい 引き込ま れる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>の 感じ でし た が 、 ４ で xxunk と 思い き xxunk だの 近未来 の 映画 に 変わり すごく 残念 です 。 xxbos 映画 は xxunk 商業 です から 、 「 商業 映画 」 で いい と 考え て い ます 。 が 、 今回 は 残念 と しか 言え ず 、 、 。 正直 「 小栗旬 出し とけ ば 安 パイ 」 が 見え すぎ まし た 。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>と 登場人物 が 同じ な のに 全然 別物 作品 じゃ ない の ・ ・ ・ ？ うじうじ し て 頼り ない シンジ 、 自信 過剰 だ けど 崩れる と 脆い アスカ 、 それと なに より 無機質 で クール で 無口 な レイ … その 基盤 あっ て の エヴァンゲリオン なん じゃ ない の ？ ！ それ に 今頃 新 キャラ なんて いら ない し 、 アニオタ 萌 ～ な エロい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>お 粗末 な 状態 だっ た ため 、 後半 から ネタバレ が 延々と 続い た よう な 印象 だっ た 。 もっと 仕草 に 共通点 を 持た せる とか 、 顔 の 代わり に 声 や 背後 、 電話 シーン だけ 写す とか 、 映像 表現 で 如何 よう に も 工夫 でき た はず 。 そういった 工夫 なく 、 ただ ダラダラ と 脚本 の 伏線 を 押さえ た だけ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>けど 。 神木 が やる と 正直 ちょっと 天然 な 青年 って 見える 。 瀬田宗次郎 って 表情 は いつも ニコニコ し て い て それでも 喜怒哀楽 を 表情 に 出さ ない 青年 。 これ は もう 原作 に しか でき ない 。 後 、 四乃森蒼紫 。 これ は もう 似 てる も 何 も 伊勢谷 さん が あの 衣装 が もう ｗ ｗ 問題 は 志々雄真実 。 原作 を イメージ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will initialize our model with weights from a language model trained on Japanese Wikipedia. You can download them from here and you need to place the `.pth` file in the `data/models/` directory and `.pkl` file in the `data/models/ja-wiki/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google colab notes: upload model files\n",
    "#files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM,pretrained_fnames=['ja-wiki','ja-wiki/itos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='1362', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3956ac957ec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1,1e-2,moms=(0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      90.00% [9/10 1:36:47<10:45]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.797721</td>\n",
       "      <td>2.649096</td>\n",
       "      <td>0.585284</td>\n",
       "      <td>10:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.347854</td>\n",
       "      <td>2.232138</td>\n",
       "      <td>0.625643</td>\n",
       "      <td>10:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.237379</td>\n",
       "      <td>2.108713</td>\n",
       "      <td>0.637691</td>\n",
       "      <td>10:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.148961</td>\n",
       "      <td>2.044700</td>\n",
       "      <td>0.643987</td>\n",
       "      <td>10:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.092854</td>\n",
       "      <td>2.000204</td>\n",
       "      <td>0.648571</td>\n",
       "      <td>10:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.051646</td>\n",
       "      <td>1.964949</td>\n",
       "      <td>0.652706</td>\n",
       "      <td>10:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.010329</td>\n",
       "      <td>1.935624</td>\n",
       "      <td>0.656021</td>\n",
       "      <td>10:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.972503</td>\n",
       "      <td>1.915587</td>\n",
       "      <td>0.658546</td>\n",
       "      <td>10:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.940315</td>\n",
       "      <td>1.906391</td>\n",
       "      <td>0.659713</td>\n",
       "      <td>10:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='2743', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bcf52d0e8cbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/text/models/awd_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, from_embeddings)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mnew_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhid_dp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mraw_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mnew_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mraw_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/text/models/awd_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m#To avoid the warning that comes because the weights aren't flattened.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10,3e-3,moms=(0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('ymr')\n",
    "learn.save_encoder('ymr_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = (TextList.from_df(mov_df_polar,path,cols=['text'],vocab=data_lm.vocab,processor=processor)\n",
    "                   .split_by_rand_pct(0.1)\n",
    "                   .label_from_df(cols=['rating'])\n",
    "                   .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos ・ 過去 の 行い と 罪 の 意識 から 強 さ の 裏 で 自分 の 命 を 軽 ん じ て い た 剣心 が 、 師匠 と 剣 を 交える うち に 「 死に たく ない ！ 」 「 死ね ない ！ 」 と 強く 思い 、 「 生きよう と する 意思 」 に 目覚め た こと で 本当 の 強 さ を 手 に 入れ 、</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos 率直 に 、 素直 に ・ ・ この 映画 、 不快 でし た ・ ・ 。 それ と共に 、 友人 から 聞い た 日本人差別 の 話 が 、 頭 に 甦り まし た 。 幼稚園 の xxunk の とき から の 、 xxunk が 、 xxunk の 時 、 お 父様 の 転勤 で 、 アメリカ xxup la に 、 xxunk し まし た 。 その 友人 と は</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos 「 パッチギ xxup love＆peace 」 で は 、 「 在日 は 被害者 、 日本人 は 悪者 」 という 構図 で 話 が 描か れ て い ます 。 では 、 はたして 実際 にそう だっ た の でしょ う か ？ 現在 の 朝鮮総連 の xxunk 団体 で ある 「 xxunk 」 xxunk は １ ９ ４ ６ 年 初頭 に 「 日本 の 敗戦 で 開放 さ れ た</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos 私 は 、 「 ガンダム 」 や 、 「 エヴァンゲリオン 」 等 は 、 タイトル を 知っ て いる くらい で 、 ほとんど 、 観 た 事 が ありません な ので 、 初めて 、 本作 の 「 予告 」 を 観 た 時 も 、 鼻 で 笑っ て い まし た 。 &lt;(_ _)&gt; よって 、 その 時点 で は 、 当然 、 xxunk つもり で い た</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos マーティン・スコセッシ 監督 、 レオナルド・ディカプリオ 主演 の 謎解き ミステリー 。 しかし 、 また し て も 宣伝 は 、 作品 本来 の 魅力 で は なく 、 表面 上 の ミステリー 部分 を xxup ｐｒ し て いる よう で 、 納得 でき ない ところ が あり ます 。 この 作品 は 、 伏線 の 多い ミステリー だ から こそ 、 画面 に 集中 し て もらう ため 、 そして</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder('ymr_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(\"映画すごかったよ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(\"演技が悪い\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq\n",
    "\n",
    "A sequence-to-sequence model is a model that takes a sequence of items and outputs another sequence of items using two networks that are trained end-to-end. This is perfect for machine translation since input sequences are directly related to output sequences. We will looking at preparing a dataset for Machine Translation task and implementing a seq2seq model. We will be using the parallel corpus available from [here](ftp://ftp.monash.edu/pub/nihongo/examples.utf.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corpus(corpus_path):\n",
    "    corpus = corpus_path.open().readlines()\n",
    "    data_pair = []\n",
    "    pat = r'#ID.+\\n'\n",
    "    for c in corpus:\n",
    "        if 'A: ' in c:\n",
    "            clean_c = c.replace('A: ','')\n",
    "            res = re.search(pat,clean_c)\n",
    "            clean_c = clean_c.replace(res.group(0),'').split('\\t')\n",
    "            data_pair.append((clean_c[0],clean_c[1]))\n",
    "    return pd.DataFrame(data_pair,columns=['ja','en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ja</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ムーリエルは２０歳になりました。</td>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>すぐに戻ります。</td>\n",
       "      <td>I will be back soon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>すぐに諦めて昼寝をするかも知れない。</td>\n",
       "      <td>I may give up soon and just nap instead.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>愛してる。</td>\n",
       "      <td>I love you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ログアウトするんじゃなかったよ。</td>\n",
       "      <td>I shouldn't have logged off.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ja                                        en\n",
       "0    ムーリエルは２０歳になりました。                        Muiriel is 20 now.\n",
       "1            すぐに戻ります。                      I will be back soon.\n",
       "2  すぐに諦めて昼寝をするかも知れない。  I may give up soon and just nap instead.\n",
       "3               愛してる。                               I love you.\n",
       "4    ログアウトするんじゃなかったよ。              I shouldn't have logged off."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_corpus(path/'examples.utf')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149784"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149784"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_idxs = np.random.choice(np.arange(len(df)), int(0.1*len(df)),replace=False)\n",
    "train_idxs = [i for i in np.arange(len(df)) if i not in valid_idxs]\n",
    "len(train_idxs) + len(valid_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collation function and databunch code borrowed from here: \n",
    "#https://github.com/ohmeow/seq2seq-pytorch-fastai/blob/master/seq2seq-rnn-attn.ipynb\n",
    "\n",
    "def seq2seq_pad_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=False, \n",
    "                        include_targets=True, include_lengths=False, include_masks=False,\n",
    "                        backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
    "    \n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    \n",
    "    samples = to_data(samples)\n",
    "    samples.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    \n",
    "    x_lens = [len(s[0]) for s in samples]\n",
    "    x_max_len = max(x_lens)\n",
    "    x_res = torch.zeros(len(samples), x_max_len).long() + pad_idx\n",
    "    \n",
    "    y_lens = [len(s[1]) for s in samples]\n",
    "    y_max_len = max(y_lens)\n",
    "    y_res = torch.zeros(len(samples), y_max_len).long() + pad_idx\n",
    "    \n",
    "    if backwards: pad_first = not pad_first\n",
    "        \n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            x_res[i,-len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,-len(s[1]):] = LongTensor(s[1])\n",
    "        else:         \n",
    "            x_res[i,:len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,:len(s[1]):] = LongTensor(s[1])\n",
    "            \n",
    "    if backwards: res = res.flip(1)\n",
    "        \n",
    "    x = [x_res]\n",
    "    if (include_targets): x += [y_res.clone()]\n",
    "    if (include_lengths): x += [torch.tensor(x_lens), torch.tensor(y_lens)]\n",
    "    if (include_masks): x += [x_res != pad_idx, y_res != pad_idx]\n",
    "    \n",
    "    return x, y_res\n",
    "\n",
    "\n",
    "class Seq2SeqDataBunch(DataBunch):\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, \n",
    "               path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1, pad_first=False, \n",
    "               device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
    "        \n",
    "        \"\"\"Function that transform the `datasets` in a `DataBunch` for seq2seq task. \n",
    "        Passes `**dl_kwargs` on to `DataLoader()`\"\"\"\n",
    "        \n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        \n",
    "        collate_fn = partial(seq2seq_pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        \n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        \n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = Tokenizer(lang='en')\n",
    "en_procs = [TokenizeProcessor(tokenizer=en_tok, include_bos=True, include_eos=True), \n",
    "            NumericalizeProcessor(min_freq=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(MeCabTokenizer, 'ja')\n",
    "ja_procs = [TokenizeProcessor(tokenizer=tokenizer,include_bos=True, include_eos=True), NumericalizeProcessor(max_vocab=30000,min_freq=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_il = Seq2SeqTextList.from_df(df, path, cols=['en'], processor=en_procs).process().split_by_idxs(train_idxs,valid_idxs)\n",
    "ja_il = Seq2SeqTextList.from_df(df, path, cols=['ja'], processor=ja_procs).process().split_by_idxs(train_idxs,valid_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ll = LabelList(en_il.train,ja_il.train)\n",
    "val_ll = LabelList(en_il.valid,ja_il.valid)\n",
    "lls = LabelLists(path,train=tr_ll,valid=val_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_data = lls.databunch(bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj muiriel is 20 now . xxeos,\n",
       " Text xxbos ムーリエル は ２ ０ 歳 に なり まし た 。 xxeos)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_data.train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecs,_,dim_en_vec = load_vectors('data/wiki-news-300d-1M.vec')\n",
    "j_vecs,_,dim_j_vec = load_vectors('data/cc.ja.300.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    if vecs is None: return emb\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w])\n",
    "        except: miss.append(w)\n",
    "    print('Number of unknowns in data: {}'.format(len(miss)))\n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
    "def rand_p(*sz): return nn.Parameter(rand_t(*sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttention(nn.Module):\n",
    "    def __init__(self,int2en,int2j,em_sz,j_vecs=None,en_vecs=None,nh=128,out_sl=25,dropf=1,nl=2):\n",
    "        super().__init__()\n",
    "        #encoder\n",
    "        self.nl,self.nh,self.em_sz,self.out_sl = nl,nh,em_sz,out_sl\n",
    "        self.emb_enc = create_emb(en_vecs,int2en,em_sz)\n",
    "        self.emb_drop = nn.Dropout(0.15*dropf)\n",
    "        self.encoder = nn.GRU(em_sz,nh,num_layers=nl,dropout=0.25*dropf, bidirectional=True,batch_first=True)\n",
    "        #decoder\n",
    "        self.emb_dec = create_emb(j_vecs,int2j,em_sz)\n",
    "        self.decoder = nn.GRU(em_sz,nh*2,num_layers=nl,dropout=0.25*dropf,batch_first=True)\n",
    "        self.out_drop = nn.Dropout(0.35*dropf)\n",
    "        self.out = nn.Linear(nh*2,len(int2j))\n",
    "        #attention layer\n",
    "        self.W1 = rand_p(nh*2, nh*2) #parameter\n",
    "        self.l2 = nn.Linear(nh*2, nh*2)\n",
    "        self.l3 = nn.Linear(em_sz+nh*2, em_sz)\n",
    "        self.V = rand_p(nh*2) #parameter\n",
    "        self.targets = None\n",
    "    \n",
    "    def forward(self,inp,y=None):\n",
    "        self.targets = y\n",
    "        bs,sl = inp.size()\n",
    "        emb_in = self.emb_drop(self.emb_enc(inp))\n",
    "        h_n = self.initHidden(bs)\n",
    "        enc_out, h_n = self.encoder(emb_in,h_n)\n",
    "        h_n = h_n.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
    "        \n",
    "        dec_inp = torch.zeros(bs).long().cuda()\n",
    "        res,attns = [], []\n",
    "        #multiply by parameter\n",
    "        w1e = enc_out @ self.W1\n",
    "        for i in range(self.out_sl):\n",
    "            #linear layer \n",
    "            w2h = self.l2(h_n[-1])\n",
    "            #non-linear activation to calculate score\n",
    "            u = torch.tanh(w1e + w2h.unsqueeze(1))\n",
    "            #softmax to make them into probs\n",
    "            a = F.softmax(u @ self.V, 0)\n",
    "            attns.append(a)\n",
    "            #multiply each vector by scores and then add them up\n",
    "            Xa = (a.unsqueeze(2) * enc_out).sum(1)\n",
    "            dec_emb = self.emb_dec(dec_inp)\n",
    "            #linear layer to reduce dimensions\n",
    "            wgt_enc = self.l3(torch.cat([dec_emb, Xa], 1))\n",
    "            outp,h_n = self.decoder(wgt_enc.unsqueeze(1),h_n)\n",
    "            outp = self.out(self.out_drop(outp[:,0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = outp.data.max(1)[1]\n",
    "            if i >=self.targets.size(1):break\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (random.random() > 0.5) and self.targets is not None: dec_inp=y[:,i] \n",
    "        return torch.stack(res).transpose(1,0)\n",
    "        \n",
    "    def initHidden(self,bs):\n",
    "        return torch.zeros([self.nl*2,bs,self.nh]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    bs,sl = target.size()\n",
    "    bs_in,sl_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,sl-sl_in,0,0))\n",
    "    input = input[:,:sl,:]\n",
    "    return F.cross_entropy(input.contiguous().view(-1,nc), target.contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherForcingCallback(LearnerCallback):\n",
    "    learn:Learner\n",
    "        \n",
    "    def on_batch_begin(self, train, **kwargs):\n",
    "        learn.model.targets = kwargs['last_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqAttention(\n",
       "  (emb_enc): Embedding(21395, 300, padding_idx=1)\n",
       "  (emb_drop): Dropout(p=0.15)\n",
       "  (encoder): GRU(300, 128, num_layers=2, batch_first=True, dropout=0.25, bidirectional=True)\n",
       "  (emb_dec): Embedding(30004, 300, padding_idx=1)\n",
       "  (decoder): GRU(300, 256, num_layers=2, batch_first=True, dropout=0.25)\n",
       "  (out_drop): Dropout(p=0.35)\n",
       "  (out): Linear(in_features=256, out_features=30004, bias=True)\n",
       "  (l2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (l3): Linear(in_features=556, out_features=300, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq = Seq2SeqAttention(seq2seq_data.train_ds.x.vocab.itos,seq2seq_data.train_ds.y.vocab.itos,300,en_vecs=None,j_vecs=None)\n",
    "seq2seq.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(seq2seq_data,seq2seq)\n",
    "learn.loss_func = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.callbacks.append(TeacherForcingCallback(learn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      40.00% [2/5 07:40<11:31]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.339883</td>\n",
       "      <td>2.918007</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.839581</td>\n",
       "      <td>2.631924</td>\n",
       "      <td>03:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='2106', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-298-8d451ab2bd28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-292-55a6db7275b7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, y)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mwgt_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdec_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXa\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0moutp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwgt_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mdec_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 3e-3, moms=(0.7,0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
